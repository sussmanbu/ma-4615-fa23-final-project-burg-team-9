[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "The data was originally found on Kaggle.com and then source data was later found on the following dataMontomery website. This data is updated frequently, our dataset is from November 3rd, 2023. The data was originally collected by the Montgomery County Police Station in Maryland. It was collected for the purpose of observing drug and traffic violations and creating a government and police record of violations. It was put together using traffic violation information from all electronic traffic violations issued in Montgomery County.\nThe data file that was used was originally in the form of a CSV file. This original dataset had 43 variables, but because it was large, we chose to use only the more relevant 14 variables in our cleaned data set, which are Date of stop, Time of stop, Description, Location, Accident, Fatal, Alcohol, Driver’s License State, Year, Make, Model, Violation type, Race, and Arrest type. Description shows what the specific charge was, such as exceeding the posted speed limit. Location indicates the specific street in Montgomery County where the violation occurred, while Driver’s License State shows the state where the driver is from, which is not necessarily Maryland. Make and Model refers to the car that was being driven. Fatal and Alcohol only say Yes or No, while Violation Type and Arrest Type provide more specific descriptions of the violation that occurred and its outcome, respectively.\nFor preliminary cleaning, we removed columns that we believe would not be helpful or relevant in our data analysis in our cleaning script. Some examples of this are latitude and longitude coordinates. No additional R packages were requrired for this and no other data sets were merged with the current data."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\n\nAn Initial Exploration Before Delving into Analysis: Motivation, Interests, Questions\nIn our pursuit of comprehensively understanding and analyzing the determinants of traffic accidents in Montgomery County, we initiated our investigation by designating “Accident” as the focal point in our dataset. Subsequently, we systematically identified and extracted additional factors we deemed potentially correlated with traffic accidents. Following a meticulous process of data screening and cleansing, we discerned that certain variables held particular significance in influencing the likelihood of accidents. Notably, these pivotal factors encompassed “Race,” “Alcohol,” “Gender,” and “Arrest Type”.\nFor further analysis, we combined a second dataset from Montgomery County which contained data about traffic violations and selected for race, alcohol/substance abuse, type (crash or traffic violation), and the coordinates of the event. Using census data, the coordinates of the events were displayed over a map showing race proportions by block groups in Montgomery County.\nWith our overarching objective aimed at generating a comprehensive analysis of traffic accidents, we are interested in examining the correlation between race and traffic events. Furthermore we hope to uncover and analyze any potential racial bias, whether intentional or not, in these traffic violations and accidents, specifically through the possible over-representation of traffic events in the most “non-White” areas. This concept not only harmonizes with the thesis statement established at the outset but also underscores the practical significance of race as the most overtly discernible variable. In a holistic sense, delving into the interplay between race and accidents could help Montgomery identify and reform any unconscious bias and possibly help them implement effective strategies to address this and improve traffic conditions at the same time. Building upon this conceptual foundation, we build our primary analysis direction: “What correlations can be identified between Race and Accident?”\n\n\nInvestigating Correlations Between Race and Traffic Incidents\nIn our gathered datasets, the racial demographics in Montgomery County were delineated into six primary categories: Asian, White, Black, Hispanic, Native American, and other. It is evident that each of these population segments experiences varying levels of accident rates. To delve into the specifics, we sought to ascertain the respective crash rates for each population group, aiming to discern the percentage contribution of traffic accidents within the county. Guided by this objective, we meticulously crafted an initial visual representation in the form of a pie chart.\n\nsuppressPackageStartupMessages(library(dplyr)) \nsuppressPackageStartupMessages(library(ggplot2)) \nsuppressPackageStartupMessages(library(stringr)) \n\ncrash_data &lt;- read.csv(here::here(\"dataset-ignore\", \"Crash_Reporting_-_Incidents_Data.csv\"))\nload(here::here(\"dataset\", \"traffic_violations.RData\"))\ndf &lt;- traffic_data_clean\nRace &lt;- df$Race\nAlcohol &lt;- df$Alcohol\nGender &lt;- df$Gender\nArrest_type &lt;- df$`Arrest Type`\nState &lt;- df$`DL State`\nAccident&lt;- df$Accident\nsubset1 &lt;- subset(df,df$Accident == \"Yes\")\nRACE &lt;- subset1$Race \nACCIDENT &lt;- subset1$Accident\nContengency_table3 &lt;- table(RACE,ACCIDENT)\n# print(Contengency_table3)\nContingency_df3 &lt;- as.data.frame(as.table(Contengency_table3))\ncolnames(Contingency_df3) &lt;- c(\"Race\", \"Accident\", \"Count\")\nratio_df3 &lt;- Contingency_df3 %&gt;%\n  mutate(ratio = Count / sum(Count))\nplot2 &lt;- ggplot(ratio_df3, aes(x = \"\", y = ratio, fill = Race)) +\n  geom_bar(stat = \"identity\") +coord_polar(\"y\", start = 0) +\n  labs(title = \"Distribution of Traffic Accidents by Race in Montgomery County\n\", fill = \"RACE\") +   geom_text(aes(label = paste0(round(ratio*100, 2), \"%\")),position = position_stack(vjust = 0.3))+\n  theme_void()\nplot2\n\n\n\n\nFigure 1. Distribution of Traffic Accidents by Race in Montgomery County\nThe pie chart provides a clear visualization of the distribution of traffic accidents by race in Montgomery County. Notably, the largest share is attributed to the White race, comprising 34.69% of all accidents. Following closely, the Hispanic and Black races account for 28.94% and 25.45%, respectively. Conversely, the percentages for Asian, Native American, and other races are notably lower, with Native American accidents registering at just 0.18%. This observed pattern aligns with expectations, given the demographic composition of Montgomery County. Whites, Blacks, and Hispanics, as the predominant ethnic groups, naturally exhibit a higher percentage of accidents due to their larger population size. In contrast, minority groups, such as Asians, contribute proportionally fewer accidents, reflecting their relatively smaller population presence.\nBuilding on the preceding analysis, it is evident that the White ethnicity exhibits the highest percentage of traffic accidents, underscoring its significance as a primary focal point for traffic regulation considerations. While acknowledging this finding, it is essential to recognize that the accident distribution may not provide sufficient insights for formulating valuable recommendations as government initiative references. Therefore, to discover more valuable information, our research focus pivoted toward examining the percentage of traffic accidents within each race. This shift aims to uncover potential disparities in traffic accident rates across different racial groups, fostering a more comprehensive understanding to inform targeted and equitable interventions.\n\nContengency_table4 &lt;- table(Race,Accident)\nContingency_df4 &lt;- as.data.frame(as.table(Contengency_table4))\ncolnames(Contingency_df4) &lt;- c(\"Race\", \"Accident\", \"Count\")\nratio_df4 &lt;- Contingency_df4 %&gt;%\n  group_by(Race) %&gt;%\n  mutate(ratio = Count / sum(Count))\nfiltered_data &lt;- ratio_df4 %&gt;% \n  filter(Accident == \"Yes\")\nRace_Accident_plot &lt;- ggplot(filtered_data, aes(x = Race, y = ratio, fill = Accident)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(aes(label = scales::percent(ratio)), \n            position = position_dodge(width = 0.8), vjust = -0.5) +\n  labs(title = \"Traffic Accident Rates Across Racial Groups\",\n       subtitle = \"The Relative Ratios of Accidents in Traffic Reports Among Different Racial Groups\",\n       x = \"Race\",\n       y = \"Percentage of Accidents\") +\n  theme_minimal()\nRace_Accident_plot\n\n\n\n\nFigure 2. Traffic Accident Rates Across Racial Groups\nFigure 2 presents a detailed breakdown of accident rates within each racial category, offering a nuanced perspective distinct from the overall pie chart analyzing accident counts by race. Notably, the accident rate within the White race is comparatively lower at 2.786%, while the Hispanic race exhibits a higher accident rate of 3.568%. This implies that for every 100 traffic reports concerning the Hispanic race, 3.568 accidents are recorded. Further insights reveal that, despite Native Americans and Asians experiencing a lower frequency of accidents, their accident rates are relatively elevated at 2.801% and 2.648%, respectively, in comparison to the corresponding traffic report figures for their ethnicities. Conversely, although the Black ethnic group registers the third-highest number of accidents, its accident rate is the lowest at 2.182%.\nFrom first glance at this data, one might assume that prioritizing Hispanic neighborhoods emerges as an effective strategy to reduce both the total number of accidents and the accident rate. However when we look at the locations of both crashes and violations we see a different trend.\n\nsuppressPackageStartupMessages(library(tidyverse)) \nsuppressPackageStartupMessages(library(tidycensus)) \nsuppressPackageStartupMessages(library(sf)) \n\n# census_api_key(\"d60e1c9aa5c6a445f991501def579b743fc1a5d8\", install = TRUE) \n\ncrash_data &lt;- read_csv(here::here(\"dataset-ignore\", \"Crash_Reporting_-_Incidents_Data.csv\"),          show_col_types = FALSE) \n\ncrash_data_clean &lt;- crash_data |&gt;      \n  select(Latitude,          \n         Longitude,          \n         \"Driver Substance Abuse\",            \n         \"Collision Type\") |&gt;   \n  rename(driver_substance_abuse = \"Driver Substance Abuse\", type = \"Collision Type\") \n\ntraffic_data_2 &lt;- read_csv(here::here(\"dataset-ignore\", \"Traffic_Violations_20231103.csv\"),          show_col_types = FALSE) \n\ntraffic_data_2_clean &lt;- traffic_data_2 |&gt;      \n  select(Alcohol,          \n         \"Violation Type\",          \n         Latitude,          \n         Longitude) |&gt;   \n  rename(driver_substance_abuse = \"Alcohol\", type = \"Violation Type\") \n\nv2020 &lt;- load_variables(2020, \"pl\", cache = TRUE)\n\nvars10 &lt;- c(\"P1_003N\", \"P1_004N\", \"P1_005N\", \"P1_006N\", \"P1_007N\") \n\nmd &lt;- get_decennial(geography = \"block group\", variables = vars10, year = 2020,           \n                    summary_var = \"P1_001N\", state = \"MD\", county = c(\"Montgomery county\"), \n                    geometry = TRUE) %&gt;%   \n  mutate(pct = 100 * (value / summary_value)) \n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n\ncrash_only &lt;- crash_data_clean |&gt;\n  mutate(type = \"collision\")\n\ntraffic_only &lt;- traffic_data_2_clean |&gt;\n  mutate(type = \"traffic violation\")\n\nsimplified &lt;- union(crash_only, traffic_only) |&gt;   \n  filter(between(Latitude, 38.8, 39.6), between(Longitude, -78, -76.5)) \n\nsimplified_geo &lt;- simplified |&gt;   \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\")) %&gt;%   \n  st_set_crs(4269) \n\nrace_list &lt;- c('P1_003N' = \"White alone\", \n               'P1_004N' = \"Black or African American alone\", \n               'P1_005N' = \"American Indian and Alaska Native alone\", \n               'P1_006N' = \"Asian alone\", \n               'P1_007N' = \"Native Hawaiian and other Pacific Islander alone\")\n\nggplot() + geom_sf(data = md, aes(fill = pct)) + facet_wrap(~variable, labeller = as_labeller(race_list)) + theme(text = element_text(size = 8))\n\n\n\n\nFigure 3. Map of proportion of race by block group for Montgomery County. As we can see from these maps, White people make up a large proportion of Montgomery county.\n\nggplot() + geom_sf(data = md, aes(fill = pct)) + \n  geom_sf(data = simplified_geo, aes(color = type), alpha = 0.1, size = 0.1) + \n  facet_wrap(~type) + theme(text = element_text(size = 8), legend.position = \"none\")\n\n\n\n\nFigure 4. Map of traffic violations (blue) and crash reports (pink). There is a lot of overlap between where the two occur.\nBased on Figures 3 and 4, we observe that the areas where people of color make up a higher proportion of the population and the proportion of White people seems to be the lowest, have the most traffic violations and crashes. Therefore the relative percentage of accidents for people of color may be an overestimation because their communities appear to already be policed at a higher rate, and further analysis must be done to account for this.\nThere could also be many confounding factors in this data that intertwine with race specifically. For example, one interpretation of the data could suggest that there is a need for special preventive measures in ethnic minority Native American communities due to their elevated accident rates. Instead of funding additional policing as a “preventative measure”, perhaps the driver education in communities of color might be inadequate and the government should direct their funding to better driver education programs instead.\nWith further analysis, we believe our findings could offer valuable insights and allow the Montgomery County government to make better informed decisions about government management, such as reinvesting their funding into community uplifting programs. By tailoring interventions based on the observed patterns, Montgomery County has the potential to address any unconscious bias and enhance traffic conditions, thereby reducing the likelihood of traffic accidents in the future and improving the county for all of its citizens.\n\nfilter_Arrest_type &lt;- df %&gt;%\n  filter(str_detect(`Arrest Type`, \"Marked|Unmarked\"))\nfilter_Arrest_type$`Arrest Type`&lt;-ifelse(grepl(\"Marked\", filter_Arrest_type$`Arrest Type`), 1, 0)\nfilter_Gender &lt;- filter_Arrest_type %&gt;%\n  filter(str_detect(Gender, \"F|M\"))\nmydata &lt;- filter_Gender\nTime_table &lt;- data.frame(mydata$`Date Of Stop`,mydata$Accident,mydata$Race)\n\nTime_table$DateOfStop &lt;- as.Date(Time_table$mydata..Date.Of.Stop., format = \"%m/%d/%Y\")\ntime_table &lt;- Time_table%&gt;%\n  filter(mydata.Accident == \"Yes\")\ncolnames(time_table) &lt;- c(\"Date of Stop\", \"Accident frequency\",\"Race\",\"Dates\")\nagg_data &lt;- time_table %&gt;%\n  mutate(month_year = format(Dates, \"%Y-%m\")) %&gt;%\n  group_by(month_year,Race) %&gt;%\n  summarise(Count = n())\nagg_data_after_2017&lt;- agg_data[451:nrow(agg_data), , drop = FALSE]\ntotal_plot &lt;- ggplot(agg_data_after_2017, aes(x = as.Date(paste0(month_year, \"-01\")), y = Count, group = Race)) +\n  geom_point(color = \"lightblue\", size = 3) + \n  geom_line(color = \"red\", size = 1) +\n  facet_wrap(~Race, scales = \"free_y\", ncol = 2) +\n  labs(title = \"Monthly Distribution of Traffic Accidents Across Racial Groups\",\n       x = \"Month\",\n       y = \"Count\") +\n  theme_minimal() +\n  scale_x_date(date_labels = \"%Y-%m\", date_breaks = \"3 months\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\ntotal_plot \n\n\n\n\nFigure 5. Monthly Distribution of Traffic Accidents Across Racial Groups\nTo gain a comprehensive understanding of the relationship between race and traffic incidents, we sought to enrich our analysis by integrating additional factors. This approach allows us to explore diverse perspectives and uncover potential patterns. Following a meticulous screening process, we identified “Date Of Stop” as a pivotal time variable. By utilizing this variable, we aimed to construct a meaningful time series plot, focusing on monthly intervals. Simultaneously, given the extensive timeframe of our database spanning from January 2012 to November 2023, we recognize that the analytical significance diminishes with an overly prolonged duration. To maintain the relevance and timeliness of our analysis, we have opted to focus exclusively on the most recent five years of data. Thus, our selected timeframe for constructing the time series plot encompasses data from January 2019 to November 2023.\nUpon close examination of the time series plot we generated, a significant trend became apparent: a notable decline in traffic accidents for all race groups, with the exception of the hispanic, starting in 2020. We posit that this noteworthy shift is attributed to the global pandemic sparked by the novel coronavirus in 2019. The widespread impact of the pandemic, coupled with governmental travel restrictions, is believed to have contributed to a substantial decline in travel frequency and, consequently, a noticeable decrease in the overall incidence of traffic accidents.\nMoreover, scrutinizing the frequency of traffic incidents post-2020, a noteworthy pattern emerged across all racial groups: a substantial uptick in accidents around January and around July, in contrast to other time periods. Following deliberation, we posit that this observed phenomenon is linked to distinct seasonal trends. Specifically, during January, coinciding with the Christmas holiday season, heightened activities such as shopping, dining, and increased outings likely contribute to the surge in incidents. Similarly, around July, the summer season prompts a notable increase in travel, further influencing the elevated frequency of traffic incidents across diverse racial demographics.\nDrawing insights from the aforementioned analysis, we contend that enhancing traffic supervision during the months around January and July can prove effective in mitigating the occurrence of traffic accidents. Simultaneously, considering strategic adjustments to holidays and moderating the intensity of traffic supervision during other periods can assist the government in alleviating management pressures and optimizing administrative efficiency. This nuanced approach aims to strike a balance between bolstering road safety and optimizing resource utilization within the broader framework of traffic management.\n\n\nConstructing and Analyzing a Logistic Regression Model\nAfter conducting an in-depth examination of the variable “Race,” we recognized that the remaining influential variables were primarily binary variables. Considering the limited depth of analysis achievable through visualization alone, we opted for a unified approach. Our decision involved constructing a comprehensive model to collectively analyze all factors influencing the occurrence of accidents. Given that our dependent variable, “accident”, is also binary, we ultimately selected the logistic regression modeling technique to predict the probability of accidents.\nOur finalized model incorporates the following variables:\nIndependent Variables: Race: Encompassing six categories—White, Black, Asian, Hispanic, Other, and Native American. Alcohol: Categorized as either “Yes” or “No.” Gender: Distinguished between “Male” and “Female.” Arrest Type: Classifying administrative forces into “Marked” and “Unmarked” based on the presence or absence of government markings on the recording vehicles. In the model, “Marked” is denoted as 1, and “Unmarked” as 0.\nDependent Variable: Accident: Assigned a value of 1 for traffic reports indicating an accident (Yes) and 0 for those without an accident (No).\n\nrace &lt;- mydata$Race\nalcohol &lt;- mydata$Alcohol\ngender &lt;- mydata$Gender\narrest_type &lt;- mydata$`Arrest Type`\n\nX &lt;- data.frame(race,alcohol,gender,arrest_type)\nY &lt;-ifelse(mydata$Accident==\"Yes\",1,0)\nsplit_index &lt;- sample(1:length(race), size = floor(0.8 * length(race)))\nx_train &lt;- X[split_index, ]\nx_test &lt;- X[-split_index, ]\ny_train &lt;- Y[split_index]\ny_test &lt;- Y[-split_index]\nmodel &lt;- glm(y_train ~ ., data = cbind(y_train, x_train), family = \"binomial\")\nsummarytable&lt;- summary(model)\n# summarytable\ncoefficients &lt;- coef(model)\nvariable_names &lt;- names(coefficients)\nimportances &lt;- data.frame(\n  'Attribute' = variable_names,\n  'Importance' = coefficients\n)\nFeature_importance_table &lt;- ggplot(importances, aes(x = Attribute, y = Importance, fill = Importance &gt; 0)) +\n  geom_bar(stat = \"identity\", color = \"lightblue\") +\n  geom_text(aes(label = round(Importance, 2)), vjust = -0.5, color = \"black\", size = 3) +  # Add this line\n  scale_fill_manual(values = c(\"lightgreen\", \"yellow\")) + \n  labs(title = \"Feature importances of the logistic model coefficients\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 60, hjust = 0.5)) +\n  xlab(\"Attribute\") +\n  ylab(\"Importance\")\nFeature_importance_table\n\n\n\n\nFigure 6. Assessing the Significance of Features in the Logistic Regression Model\nConsidering that the variables analyzed in our model are derived from the traffic report dataset we collected, it’s crucial to acknowledge that accident rates are influenced by a myriad of factors beyond the scope of our dataset, including politics, lifestyle, and traditional culture. Instead of fixating on aspects like model improvements and errors, our emphasis shifts toward understanding the individual impact of each variable revealed by the model on the occurrence of accidents. Building on this foundation, we visually depict the significance of each coefficient in the model, illustrating their positive or negative impact on the accident probabilities.\nFrom Figure 6, first we can observe that the intercept in the logit regression model is substantially negative large, which indicates that the baseline effect of the logit is robust and proves that the probability of error is still relatively small overall.\nIn examining the selected factors, certain patterns emerge in their impact on the probability of accidents. Notably, instances involving a marked arrest type, the presence of alcohol, male gender, and individuals identified as White, Hispanic, or Native American tend to elevate the probability of accident. Among these variables, the presence of alcohol exerts the most substantial effect, contributing to a 1.62 increase in log-odds. Following closely, marked arrest type and Hispanic Race exhibit the second and third most significant impacts, with effects on log-odds amounting to 0.45 and 0.32, respectively. Moveover, certain factors are associated with a lower likelihood of increased accident rates. Specifically, male, identifying as Native American or White correspond to more modest effects on log-odds, measuring at 0.06, 0.01, and 0.07, respectively. The remaining factors, which generally diminish the probability of accident, exhibit relatively minor effects. Specifically, Black race demonstrates a modest negative effect of 0.19 on log-odds, while the Other race exhibits an even smaller effect of 0.09.\nIn summary, our logistic regression model highlights distinctive patterns in the impact of various variables on the probability of accident. Female gender, Asian race, unmarked arrest type, and the absence of alcohol do not exhibit a significant influence on accident rates. However, the majority of variables, except for Black Race and Other Race, display a propensity to increase the odds of accidents with a positive effect. This nuanced understanding, derived from our model’s analysis, offers valuable insights for Montgomery County. The findings can serve as a strategic reference point for comprehensively assessing traffic conditions, facilitating informed decisions in traffic scheduling, and guiding initiatives to effectively mitigate the probability of accidents.\nWe think it is important to note that this data is likely biased based on the distribution of police in predominantly White and non-White neighborhoods. The preliminary analysis of the data assumes that the total population is equally distributed across the county and therefore the density of traffic reports and accidents is correlated with race. We believe further analysis is necessary to make any definite conclusions. More detailed data about population distribution and a map of all roads in Montgomery could help provide more insight into the possible effect of race on traffic crashes and violations."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Blog Post 7\n\n\nTentative Thesis, Evidence, and Next Steps\n\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nTeam 9\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 6\n\n\nCurrent Model Analysis and Next Steps\n\n\n\n\n\n\n\n\n\nDec 4, 2023\n\n\nTeam 9\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 5\n\n\nSecond Dataset for Analysis and Combining Datasets\n\n\n\n\n\n\n\n\n\nNov 22, 2023\n\n\nTeam 9\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 4\n\n\nExploratory Data Analysis and Initial Statistical Modeling\n\n\n\n\n\n\n\n\n\nNov 13, 2023\n\n\nTeam 9\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 3\n\n\nData Cleaning and Unusal Value Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nTeam 9\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 2\n\n\nIntial Data Cleaning and Equitable Data Practice\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nTeam 9\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 1\n\n\nPotential Datasets for Analysis\n\n\n\n\n\n\n\n\n\nOct 20, 2023\n\n\nTeam 9\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-11-06-blog-post-3/blog-post-3.html",
    "href": "posts/2023-11-06-blog-post-3/blog-post-3.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "library(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.1\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.3.1\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'purrr' was built under R version 4.3.1\n\n\nWarning: package 'dplyr' was built under R version 4.3.1\n\n\nWarning: package 'stringr' was built under R version 4.3.1\n\n\nWarning: package 'forcats' was built under R version 4.2.3\n\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nload(\"C:/Users/pfwan/OneDrive/Desktop/MA 615/ma-4615-fa23-final-project-burg-team-9/dataset/traffic_violations.RData\")\nmydata &lt;- traffic_data_clean\n\nstate_counts &lt;- mydata %&gt;% \n  group_by(`DL State`) %&gt;%\n  summarise(count= n()) %&gt;% \n  arrange(desc(count))\n\nplot1 &lt;- ggplot(state_counts, aes(y=reorder(`DL State`, count),x=count)) + \n  geom_bar(stat = \"identity\") +\n  labs(title = \"The Count of DL state appear times\", x = \"DL State\", y = \"Count numbers\") + theme_minimal() +\n  theme(axis.text.y =element_text(size = 4)) +theme(plot.background = element_rect(fill = \"white\"))\nplot1\n\n\n\nggsave(\"blog plot1 .png\", plot1, width = 8, height = 4, units = \"in\")\n\n\nstate_percentage &lt;- mydata %&gt;% \n  group_by(`DL State`) %&gt;%\n  summarise(count = n()) %&gt;%\n  mutate(percentage = (count / sum(count)) * 100) %&gt;%\n  arrange(desc(count)) %&gt;%\n  mutate(state_group = ifelse(percentage &lt; 1, \"other\",`DL State`)) %&gt;%\n  group_by(state_group) %&gt;%\n  summarise(count = sum(count), percentage = sum(percentage))\n\n\nplot2 &lt;- ggplot(state_percentage, aes(x = \"\", y = percentage, fill = state_group)) +\n  geom_bar(stat = \"identity\") +coord_polar(\"y\", start = 0) +\n  labs(title = \"State Count Percentages\", subtitle = \"All states have percentage less than 1 grouped as 'other'\",fill = \"State\") +   geom_text(aes(label = paste0(round(percentage, 1), \"%\")),position = position_stack(vjust = 0.5))+\n  theme_void()+theme(plot.background = element_rect(fill = \"white\"))\nplot2\n\n\n\nggsave(\"blog plot2 .png\", plot2, width = 8, height = 4, units = \"in\")\n\nAfter reviewing our initial subset of data, we decided to add back some columns we previously removed as we believe they could potentially have an interesting and significant correlation with race, and we had space to incorporate these columns while keeping our subset of data under 50 MB. The columns include: Time of stop, Accident, Fatal, Alcohol, Driver’s License State, and Model. During our basic exploratory data analysis we noticed that the Driver’s License State is predominantly Maryland. While this is an unusually high frequency for one state, in the context of our data it makes sense because our data was collected by the Montgomery County, Maryland Police department.\nAfter thorough discussion and analysis of our filtered data, we have identified a crucial area for investigation: the potential relationship between drivers’ race and their original state. This exploration has the potential to significantly benefit local government statistics, enhance their understanding of the local traffic landscape, and ultimately improve work efficiency. In order to achieve this goal, visualizing the driver state and evaluating the outliers and data distribution in this variable are the first steps we need to take.Thus, we have chosen to use DL State, representing the state of the driver’s home address, rather than the variable State, which denotes the state where the vehicle is registered as our plot parameter.\nDepending on the graph “blog plot1” we build, the data presented in this graph shows that Maryland (MD) has a significantly larger volume of data compared to any other state, even the combined data from all other states.Furthermore, the pie chart “blog plot2” that using the state percentage,where categorizes states with a percentage less than 1 as “other”, also shows that the percentage of MD is 87 percent, a very unusual high value. After discussion, we believe that the main reason for this phenomenon is that our dataset primarily consists of daily statistics from Montgomery County, Maryland, so a large portion of the data originating from Maryland residents is reasonable.\nAfter further research on how to clean up this part of the data, we believe that it should be handled differently based on the consideration of other variables, especially the distribution of race. If we focus our research on the race of Maryland natives,we can treat data from other states as outliers or unusual values and consider cleaning them up. However, if we focus on the involving out-of-state drivers race, the data from Maryland should be seen as a substantial influence on the model’s accurate representation of unusual outliers.Given that we have not fully explored their potential connections to other factors, their potential prior connections to other factors, and that neither the feasibility of other factors as model variable nor the data cleanup considerations have been fully completed, we have decided not to undertake data cleaning for the unusual values presented in this chart.\nIn our next step, some important topics will be discussed: the race proportion of driver’s and its relationship between Arrest type and State, and the potential linear relationship between Race, DL states and Violation Type. All data cleaning will be gradually determined and implemented in subsequent discussions."
  },
  {
    "objectID": "posts/2023-10-20-blog-post-1/blog-post-1.html",
    "href": "posts/2023-10-20-blog-post-1/blog-post-1.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "Traffic and Drugs Related Violations Dataset https://www.kaggle.com/datasets/shubamsumbria/traffic-violations-dataset/data This data set has 15 columns and 52,967 rows. The data was originally collected to record observations of traffic and drugs violations. This dataset is in the form of a CSV file, so we will be able to load and clean the data. The main question we hope to address is if one race has more traffic and drugs related violations than the other race categories. Another question we hope to address is if the outcome of the violation is different for a certain race category than it is for others, such as if people in one race were more or less likely to be arrested. We will also aim to answer this in terms of if a certain violation category more frequently resulted in a type of outcome as well. A challenge that we may come across is in organizing the data since it looks like the data may contain repeats of the same violator when there were multiple records of a violation, whether the same or different type, for one person. An additional challenge that might come up when analyzing this dataset is from the missing values in some columns which could make it more difficult to see connections.\nPeople Receiving Homeless Response Services by Age, Race, Ethnicity, and Gender - Homelessness Demographic By Race https://catalog.data.gov/dataset/people-receiving-homeless-response-services-by-age-race-ethnicity-and-gender-b667d This data set has 5 columns and 2162 rows. The data was originally collected by 44 Continuums of Care (CoC) in California, which are regional planning bodies and service coordinators for homelessness care, and the data is about the people the centers serve to help them learn more about their demographics. The data is a CSV file so it can be loaded into R Studio and cleaned. We hope to address with this data set if one race receives more care for homelessness than other races across all the CoC centers in California, if there are any trends in the number of people of each race receiving care (is it increasing, decreasing, or steady), and if one region serves a larger population of homeless people than other regions. A challenge that might come up in the future is the data set does not have a lot of information so more complex analysis of the data might be limited. The data also seems to include age, ethnicity, and gender information but in different CSV files so we were wondering if there was a way for us to combine this information.\nNCHS - Death rates and life expectancy at birth https://catalog.data.gov/dataset/nchs-death-rates-and-life-expectancy-at-birth This data set has 5 columns and 1072 rows. FIve columns consist of Year, Race, Sex, Average Life Expectancy in Years, and Age-adjusted Death Rate. This dataset tracked U.S. mortality trends from 1900 to 2017. It highlights the differences in age-adjusted death rates and life expectancy at birth by race and sex. Using this dataset, we hope to discover any correlation between race and life expectancy. Of course, there are multiple factors that we cannot take into our consideration, but we believe that at least some kind of trend should be visible with R. As time progresses, the medical care people receive should have been better than before. This means life expectancy would go up, but that would vary among different races and there is a difference between who can receive the care and who cannot. It is true that it would have been better if there were more columns and rows; however, it would be interesting to extract good information from a small sample of data. If this data does not work, we hope to find better datasets from online."
  },
  {
    "objectID": "posts/2023-12-11-blog-post-7/blog-post-7.html",
    "href": "posts/2023-12-11-blog-post-7/blog-post-7.html",
    "title": "Blog Post 7",
    "section": "",
    "text": "Our tentative thesis statement is that non-white populations of Montgomery County, Maryland have more instances of traffic violations when compared to areas of the county that are predominantly white. After our exploratory data analysis, we noticed patterns between race dispersity and location from our longitude and latitude data columns. This became more evident in our plots showing the map of Montgomery County, in which we colored the map by the proportion of the population that is of a certain race category. Since we split this map into separate maps for each race category in our dataset, we were able to see that when we overlaid points for where the traffic violations occurred, the clusters of traffic violation incidents were generally in and around the areas where the proportion of the population that is white was the lowest, and the proportion of the population that is of different race categories is higher. Therefore, we included race as a necessary variable in our statistical model for predicting arrest types.\nWe also included alcohol and gender to improve the model’s accuracy. We chose these predictor variables to include from our exploratory data analysis as well. We could see a pattern indicating that alcohol may be related to arrest type, as well as a trend that appeared to show gender being related to arrest type as well. We additionally used AIC values to determine groupings of predictor variables to find the best fitting model for our data. Because the model using race, alcohol, and gender to predict arrest type had the lowest AIC, it confirmed to us that these variables should be included in our statistical model.\nTherefore, both our exploratory data analysis and our model center around our thesis, which states that traffic violations are more likely to occur in areas of Montgomery County, Maryland that have higher proportions of the population as racial categories other than white. After our exploratory data analysis brought these patterns and trends to our attention, we were able to create a glm model for the binomial variable arrest type. While we will continue to improve our model’s accuracy for our next steps, we aim to use this model to show our traffic violation arrest types vary by location based on the proportion of the population that is non-white, showing how different violations are more likely to occur when the highest proportion of the population of an area is non-white."
  },
  {
    "objectID": "posts/2023-10-30-blog-post-2/blog-post-2.html",
    "href": "posts/2023-10-30-blog-post-2/blog-post-2.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "Since we are working with a large data set, we needed to start with only a subset of the data. We chose this subset by including columns without common instances of missing data. We also focused on choosing columns with different variables instead of columns that generally had the same response for each row in order to be able to see more variation in patterns and trends. This managed to create a subset that is now 34.6 MB so it will be more efficient to work with, but we will be able to add in more data later in the process if needed.\nThe principles for advancing equitable data practice that are relevant to our data are mainly beneficence and justice. Beneficence is relevant because it involves data that is collected with identification. Adhering to this practice involves removing anything in our data that could be used to identify people. In order to this, we remove any violation numbers or record numbers that could be traced back to a specific person. Justice is relevant because it involves considering the community in our design interest. Adhering to this practice involves us considering how the specific community from which the data comes from will impact our analysis and keeping that in mind instead of generalizing our data.\nOne of the important principles that were discussed was transparency. In order to implement this, we will need to be transparent both about what the limits of the data we have chosen are and what data informs our analysis. This will involve documenting our process clearly along the way in terms of how we are making this analysis. Therefore, some limitations of our analysis will be that we can only create analysis in terms of the specific community that our data comes from rather than generalizing it. We will also have to be aware that there may have been biases in how the data was collected so it may not be completely accurate or representative. For example, the data recorded at night may have been less accurate than the observations collected during the day. Additionally, observations may have been more likely to be recorded for certain types of violations, for example, ones that were worse, or for certain race categories.\nTransparency also involves being clear and transparent about what the plans are for the data after the project concludes. This refers to the potential for abuse or misuse of the data if we are not cautious about who has access to the data both during and after the project is completed."
  },
  {
    "objectID": "posts/2023-11-13-blog-post-4/blog-post-4.html",
    "href": "posts/2023-11-13-blog-post-4/blog-post-4.html",
    "title": "Blog Post 4",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nload(here::here(\"dataset/traffic_violations.RData\"))\n \nwd &lt;- traffic_data_clean %&gt;% \n  rename(Arrest_Type = `Arrest Type`)\n \n# Race vs Arrest Type\nggplot(wd, aes(x = Race, fill = Arrest_Type)) + \n  geom_bar(position = \"dodge\") + \n  labs(title = \"Distribution of Race by Arrest Type\", \n       x = \"Race\", y = \"Count\",\n       fill = \"Arrest Type\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_y_continuous(labels = scales::comma)\n\n\n\n\n\nggplot(wd, aes(x = Race, fill = Accident)) + \n  geom_bar(position = \"dodge\") + \n  labs(title = \"Distribution of Race by Accident\", \n       x = \"Race\", y = \"Count\",\n       fill = \"Accident\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_y_continuous(labels = scales::comma)\n\n\n\n\n\n# Statistical Modeling\n\nlibrary(tidyverse)\n\ntraffic_data_clean &lt;- traffic_data_clean |&gt;\n  mutate(Race_binary = ifelse(Race == \"Hispanic\", 1, 0))\n\nfiltered_data &lt;- traffic_data_clean |&gt;\n  filter(Year &gt;= 2000 & Year &lt;= 2023) |&gt;\n  mutate(Numbered_Year = Year - 2000)\n\nmodel &lt;- glm(Race_binary ~ Numbered_Year, family = binomial, data = filtered_data)\n\nWarning: glm.fit: algorithm did not converge\n\nggplot(filtered_data, aes(x = Numbered_Year, y = Race_binary)) +\n  geom_point() +\n  geom_smooth(method = 'glm', formula = y ~ x, se = FALSE, color = \"blue\", size = 0.5) +\n  labs(title = \"Logistic Regression: Race_binary ~ Numbered_Year\",\n       x = \"Numbered_Year\",\n       y = \"Race_binary\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nFrom our last blog post, we saw that one of the most big, obvious trends was that the Driver’s License State category was predominantly from Maryland. Since this is to be expected given that the data is from a county in Maryland, this may be a boring part of the data. So, we chose to explore some other relationships that might be confounded by this major trend we identified.\nTo explore our data further in this way, we first looked at relationships among different variables and groupings by looking for trends or patterns between race categories and arrest types as well as race categories and accident types. We then focused on developing a better understanding of the specific relationship between race and arrest types and race and accident types by also including the time of day to see if this too affects the outcome of the traffic violation.\nBeginning to think about statistical modeling, the response variable that we are interested in is the outcome of the traffic violation, which in our data is represented as arrest type and accident type. The predictor variables we are interested in are race and time of day. To include time of day we would need to perform some transformations to better capture the relationships between the variables. Since time is going in a loop as it goes to the end of the day and then the values go back down to 0, we need to transform this column of the data to be continuous instead of a cycle. We will fit a linear model so that we can see how the predictor variables affect the response variable. For this, we will also need another transformation to represent the outcome of the traffic violation as binary variables. For the arrest type, we can choose “A – Marked Patrol” to be represented by 1, and each other arrest type to be 0. Similarly, for the accident column, we can choose “Yes” to be 1 and “No” to be 0. After these transformations, we can use the categorical variables in the linear model.\nFor our initial statistical modeling, we began by using a logistic model with the race as the response variable and the year as the predictor variable to observe the potential relationships between the differences in race categories reported for traffic violations over a number of years. For this initial modeling, we transformed the race variable to be binary by mutating “Hispanic” to be 1 and every other race category to be 0. We also transformed the Year variable to be represented as a value showing how many years from 2000 it is. We also only included the years 2000-2023 to first see how we could analyze a subset of the data on a smaller scale. For our future statistical modeling, we will also include the other race categories to see the trends and patterns between the different categories and include more years to see more widespread trends. This initial model showed a straight horizontal line after the regression, so in our further analysis we will additionally add more variables to find a model that reveals more about the data and its trends."
  },
  {
    "objectID": "posts/2023-12-11-blog-post-6/blog-post-6.html",
    "href": "posts/2023-12-11-blog-post-6/blog-post-6.html",
    "title": "Blog Post 6",
    "section": "",
    "text": "For our model, we have chosen Arrest types as our binomial response variable, which ‘marked’ arrest type as 1 and ‘Unmarked’ arrest type as type 0. Our predictor variables are Race, Alcohol, and Gender. We then used a glm model for the binomial family.\nIn the original model we generated, we have observed that except the variable “male Gender”, every other categorical variables has significant effect in the prediction of probability of our dependent model, which points out that there is relation between the categorical variables we choose and their arrest type probability.\nWhat’s more, based on the coefficient value, we can summarize that the variables “Black”,“Hispanic”,“Other” and “white” in Categorical “Race”, the variable “Alcohol” has negative log-odds, which means that will lower the probability they got arrest type as “marked”. While the variables “Male” “U” in Categorical variable”Gender”, the Race “Native American” has positive log-odds, which will increase their probability they got the arrest type as “Marked”.\nWe also built a confusion matrix to find our model accuracy. From this, our model accuracy is 0.9277944, which roughly is %92.78, when we pick the predict probability larger than 0.5 as 1 and less than 0.5 as 0. Compare with the marked and unmarked arrest type proportion, we may cautiously evaluate this model’s accuracy because we have to think about the probability of overfitting in our mode and the imbalance in our model.\nIn the model summary, we have notices that the null deviance is 984980 and residual deviance is 979510, and the deviance range is (-2.6691,1.2755), and our model may contains over fitting because of the imbalance outcome proportion in our dependent variable.\nBased on the current outcome of our origional model, to enhance the performance of our original model, we are exploring several avenues for improvement. First and foremost, our current dataset comprises solely categorical variables. Introducing relevant numerical variables could significantly augment our model’s predictive capabilities, particularly when utilizing logistic regression as our analytical framework. To achieve this, we are considering merging our existing dataset with other correlated datasets, a step we believe is crucial in uncovering additional potential relationships between the dependent and independent variables.\nAdditionally, we recognize the imbalance in our current dependent variable. To address this, we are contemplating the exploration of alternative dependent variables. Building multiple analysis models with varied dependent variables can provide a broader perspective, potentially revealing different relationships and leading to more robust conclusions. This approach not only enhances the stability of our findings but also enriches our exploratory data analysis (EDA) by fostering new insights.\nBy diversifying our dataset and exploring alternative dependent variables, we aim to refine our understanding of the underlying relationships, ultimately improving the overall performance and reliability of our analytical models.\nWe plan to polish our visualizations and tables after finalizing our model to best show the data in terms of our method of statistical modeling. This will include highlighting information that informed the variables we made the decision to include. For example, in our scatterplot from our exploratory data analysis we will highlight the variables race, alcohol, and gender which seemed to have a potential relationship with arrest_type_numeric to show that this contributed to these variables being chosen for our statistical model. We also plan to add titles to our visualizations and tables to more clearly show what is being modeled in that particular plot.\nAdditionally, we will polish up our data visualizations by adding captions and annotations to write a short summary of what our takeaways from that visualization were. For example, in the scatterplot mentioned before we will add a caption or annotation saying that only race, alcohol, and gender appear to potentially have a relationship with arrest_type_numeric. We also plan to improve our figures using the options for displaying tables from https://gallery.htmlwidgets.org/, particularly the scatterD3 option to include both colors and comments more clearly for specific points in our plots. We are also planning to use pairsD3 to be able to show various relationships between variables that we explored to choose our model.\nWe are still trying out different EDA, with GLM being the priority. We are still unsatisfied with produced results, but we believe we could reach a conclusion that everyone can agree."
  },
  {
    "objectID": "posts/2023-11-22-blog-post-5/blog-post-5.html",
    "href": "posts/2023-11-22-blog-post-5/blog-post-5.html",
    "title": "Blog Post 5",
    "section": "",
    "text": "Acknowledging our dataset’s origins in Montgomery’s daily traffic records, , If we want to find possible datasets to combine with, we believe that focusing on the data resource from different aspects of Montgomery is a good starting point. After primary discussion, We decided to identify location-related factors as the main combine factor objects. Government’s official dataset, replete with detailed location coordinates, longitude, latitude, and street names, will be the prime candidates for dataset combination.\nUpon thorough exploration, two datasets, Crash Reports surfaced as an ideal contender for combination. In previous discussions and studies, we decide to focus towards understanding the intricate relationship between arrest types and accident types, with race as a central analytical factor. The “Crash Report” dataset stood out due to its comprehensive details on accidents, including location specifics such as intersections, weather conditions, and collision types. This richness in data allows for a more nuanced construction of our predictive model by incorporating variables that influence accident types. Therefore, it becomes an ideal combined dataset. ( https://data.montgomerycountymd.gov/Public-Safety/Crash-Reporting-Incidents-Data/bhju-22kf )\nGiven that both databases utilize the same record format for data collected from identical locations, various sharing factors can be considered as combined factors. After experimenting with Latitude, Longitude, and Location, the decision was reached to use Latitude and Longitude as the primary integration factors, offering the most optimal analysis environment. This choice not only ensures seamless database merging but also guarantees analysis precision. From the perspective of data visualization, using location as a combining factor can help us to generate real-world latitude/longitude charts to help us visualize the frequency of occurrence of the arrest type and accident type in each region, which will bring us more three-dimensional analysis results.On the another perspective of linear modeling, more variables can be selected and integrated to help us add more variables to our linear model and increase the accuracy of the model.\nIn conclusion, by focusing on regionally relevant factors, combining the dataset Crash reports with our original is a valuable data consolidation option.This approach not only ensures comprehensive analysis but also lays the groundwork for a more detailed and accurate predictive model. The use of Latitude and Longitude as key integration factors enhances our analytical capabilities, allowing for more insightful data visualization and improved linear modeling accuracy. While we are having difficulties joining the data by both latitude and longitude, our plan going forward is to combine the two columns into one in order to use this to consolidate the two datasets. One of the main errors we are having trouble with is that there was an unexpected many to many relationship between x and y, which we will continue to figure out going forward. In subsequent analyses, we will also consider how more specific filtering and combining datasets can take advantage of these potential strengths, detailing our analysis. In the meantime, finding more suitable data that can be used as combining objects is also a necessary step to accomplish. So far we have also searched for several usable candidates such as the dataset Crime Report. More details will be agreed upon in subsequent discussions."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team BURG. The members of this team are below."
  },
  {
    "objectID": "about.html#woo-hyeon-luke-her",
    "href": "about.html#woo-hyeon-luke-her",
    "title": "About",
    "section": "Woo Hyeon (Luke) Her",
    "text": "Woo Hyeon (Luke) Her\nWoo Hyeon is an undergraduate student studying Data Science. www.github.com/365LIT"
  },
  {
    "objectID": "about.html#megha-polavarapu",
    "href": "about.html#megha-polavarapu",
    "title": "About",
    "section": "Megha Polavarapu",
    "text": "Megha Polavarapu\nMegha Polavarapu is an undergraduate student at Boston University studying Mathematics."
  },
  {
    "objectID": "about.html#holly-gustavsen",
    "href": "about.html#holly-gustavsen",
    "title": "About",
    "section": "Holly Gustavsen",
    "text": "Holly Gustavsen\nHolly Gustavsen is an undergraduate student studying Biology at BU."
  },
  {
    "objectID": "about.html#jaejoong-kim",
    "href": "about.html#jaejoong-kim",
    "title": "About",
    "section": "Jaejoong Kim",
    "text": "Jaejoong Kim\nJaejoong Kim is an undergraduate student studying Data Science and Business at BU."
  },
  {
    "objectID": "about.html#pengfei-wang",
    "href": "about.html#pengfei-wang",
    "title": "About",
    "section": "Pengfei Wang",
    "text": "Pengfei Wang\nPengfei Wang is a graduate student studying Statistics at Boston University.\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\n\nDriving Under the Lens: Uncovering the Truth Behind Racial Disparities in Montgomery County’s Traffic Arrests\nGeorge Floyd, Eric Garner, and Michael Brown are only a few examples of the fatal incidents that highlight a dangerous prejudice persisting in the United States. The United States is composed of countless different groups made up of different identities. A significant part of these identities is race. Just within this one country, there are six racial categories, as well as people who belong to more than one race. Yet, each of these groups is looked at differently. The United States has been seen to give rise to both prominent and unconscious biases. While always present, in recent times, there has been more news regarding cases of systemic racism as seen with Floyd, Garner, and Brown. This rise in attention towards racial inequality gives rise to the question of what influences are contributing to biases, especially on how police systems may show patterns behind the variations seen in the outcomes for different races.\nThis analysis focuses on these trends, what may be influencing them, and how they then can be targeted. We focus on the police system through traffic violations specifically in the area of Montgomery County, Maryland, by analyzing information such as the types of violations, the arrest characteristics, and locations. This approach aims to uncover if and how these disparities are due to systemic issues.\n\n\nThesis For Analysis\nTraffic reports can have a variety of influences both from factors included in the data set and ones outside of it. To understand the possibilities of what is driving patterns in traffic violations, we made use of influential factors that were included in our dataset and appeared influential in our exploratory data analysis. These primarily included race, gender, if alcohol was involved in the accident, and if the violation was a car crash or a traffic violation incident. Using two datasets from Montgomery County’s records on traffic violations. Using these factors, we aimed to develop a method of modeling that would be capable of predicting accident probabilities based on these influences. This model revealed important patterns in the probabilities of accidents in Montgomery County to develop the thesis of our analysis: non-white populations of Montgomery County, Maryland have more instances of traffic violations when compared to areas of the county that are predominantly white.\nTo research this thesis, we aimed to analyze the potential relationships between traffic violations and accidents and race. The racial categories we worked with were six categories, Asian, White, Black, Hispanic, Native American, and Other. Each of these groups displayed different rates and characteristics of accidents throughout our exploratory data analysis. This was primarily shown by the visualizations below, showing the relationships between race and other variables given by our datasets. The first chart showcases the proportions of gender that were recorded to have traffic violations for each race, with the blue bars representing males and the red ones showing females. In general for each race, the larger proportion of traffic violations were for males, but the proportions did differ by race. The second chart shows the proportion of alcohol use for each race. Each race has one bar, which is colored partly blue to represent the proportion of violations that involved alcohol race, and red to show the ones that did not involve alcohol use. This chart showed that the majority of traffic violations for this county did not involve alcohol use, but the proportion that did not involve alcohol did vary by race. These exploratory plots show that there may be potential relationships between race and gender as well as race and alcohol use as well, indicating that including gender and alcohol use as predictors could be relevant.\nThe pie chart below shows the categories of violations colored to show the relative proportions of the data that fall into each category. Because there are differences between the categories, it additionally indicates that violation type may be informative in discovering patterns within the traffic violations to connect our predictions to.\n\n\nVisualizations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis Explanation\nTherefore, to discover more valuable information, we additionally expanded our analysis to include race, gender, if alcohol was involved in the accident, and if the violation was a car crash or a traffic violation incident to develop a more overarching understanding of the patterns in the datasets to provide valuable insights behind Montgomery County’s accident probabilities and their influences. These inclusions were also aimed to uncover any potential influences working in combination with race to influence accidents in the county.\nThe findings resulting from our analyses provide insights into the way that Montgomery County’s police and government systems work, and where there are limitations in the equality of their current practices, thus pointing to where improvements could be made. The information revealed from the analysis presents Montgomery County, Maryland with a better awareness of how they may be able to prevent future accidents in common areas or within common groups or reduce their likelihoods through the examination of influential factors. This gives the county the knowledge to begin considering and addressing biases that are present within their departments and decrease the consequences. The disproportional effects in different areas and groups of people shows a common issue of inequality, a danger that can motivate Montgomery County to begin implementing changes. By addressing the key issues we have identified, the county’s police department and government systems can have a strong starting point on how to address these matters. With this, Montgomery County can later investigate further into the general patterns and trends uncovered.\n\n\nGoals\nOur study aims to delve into the relationship between race and systemic inequality, while maintaining responsible data analysis, objective findings, and considering social implications. Our goal is to provide insights based on data analysis specifically regarding the disparities that the communities of Montgomery County, Maryland face in their daily lives as they commute from place to place. We aim to inform more equitable practices within police and government systems and contribute to more equitable systems. This analysis is a step towards understanding and addressing the complex realities of racial disparities in traffic violations, paving the way for future improvements and further research."
  }
]